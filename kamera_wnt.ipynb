{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import time\n",
    "\n",
    "emotion_dict={\n",
    "    'sad': 'Dlaczego taki smutny ?',\n",
    "    'angry': 'Gniew nic nie da.',\n",
    "    'surprise': 'Zaskoczony?',\n",
    "    'fear': 'Bez obaw, przyjmiemy Ciebie jak swojego.',\n",
    "    'happy': 'I o to chodzi! Witamy w KNRM !',\n",
    "    'disgust': 'Ej... no!',\n",
    "    'neutral': 'Zbyt naturalnie',\n",
    "    '': 'Ujawnij twarz :)'\n",
    "}\n",
    "emotion_dict_pl={\n",
    "    'sad': 'smutek',\n",
    "    'angry': 'gniew',\n",
    "    'surprise': 'zaskoczenie',\n",
    "    'fear': 'strach',\n",
    "    'happy': 'zadowolenie',\n",
    "    'disgust': 'zniesmaczenie',\n",
    "    'neutral': 'neutralnie',\n",
    "}\n",
    "\n",
    "path_xml = \"C:/Users/kozol/miniconda3/pkgs/opencv-4.6.0-py310ha7641e4_2/Library/etc/haarcascades/\"\n",
    "path_xml = \"C:/Users/mk/.conda/pkgs/opencv-4.6.0-py39h104de81_2/Library/etc/haarcascades/\"\n",
    "f_cascade = cv2.CascadeClassifier(path_xml + \"haarcascade_frontalface_default.xml\")\n",
    "logo = cv2.imread(\"img\\mechatronika2.png\")\n",
    "#print(logo.shape)\n",
    "# Inicjalizacja kamery internetowej\n",
    "cap = cv2.VideoCapture(0)\n",
    "t1= time.time()\n",
    "x, y, w, h = 0, 0, 0, 0\n",
    "cv2.namedWindow(\"Kamera\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "padding = 10\n",
    "color_defoult = (100, 100, 100)\n",
    "font = cv2.QT_FONT_NORMAL\n",
    "while True:\n",
    "    max_emotion=['']\n",
    "    # Pobranie klatki z kamery\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    logo_height, logo_width = logo.shape[:2]\n",
    "\n",
    "    # Określ pozycję, gdzie logo ma zostać umieszczone\n",
    "    x_offset = 550\n",
    "    y_offset = 10\n",
    "\n",
    "    # Umieść logo na obrazie z kamery\n",
    "    frame[y_offset:y_offset+logo_height, x_offset:x_offset+logo_width] = cv2.addWeighted(frame[y_offset:y_offset+logo_height, x_offset:x_offset+logo_width],0.7,logo,0.3,0)\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = f_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "    if len(faces) > 0:\n",
    "        (x, y, w, h) = faces[0]\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "        #if time.time() - t1 > 5:\n",
    "        #    t1= time.time()\n",
    "        result = DeepFace.analyze(frame, actions=['age', 'gender', 'emotion'], enforce_detection=False, prog_bar=False)\n",
    "     \n",
    "        # Pobranie emocji\n",
    "        emotions = result[\"emotion\"]\n",
    "        gender = result[\"dominant_gender\"]\n",
    "        age = result[\"age\"]\n",
    "        #dominant_emotion = result['dominant_emotion']\n",
    "\n",
    "        # Znalezienie największej wartości\n",
    "        max_value = max(emotions.values())\n",
    "        max_emotion = [k for k, v in emotions.items() if v == max_value]\n",
    "        # Wypisanie wyników na klatce\n",
    "    \n",
    "        cv2.putText(frame, \"Plec: {}\".format(gender), (10, 90), font, 0.5, color_defoult, 2)\n",
    "        cv2.putText(frame, \"Wiek: {}\".format(age), (10, 120), font, 0.5, color_defoult, 2)\n",
    "        cv2.putText(frame, \"Emocja: {}\".format(emotion_dict_pl[max_emotion[0]]), (10, 150), font, 0.5, color_defoult, 2)\n",
    "    \n",
    "        \n",
    "    else:\n",
    "        cv2.putText(frame, \"ZAPRASZAMY do KNRM \", (10, 40), font, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "\n",
    "    # Analiza klatki za pomocą deepface\n",
    "    #if DeepFace.detectFace(frame):\n",
    "    #    result = DeepFace.analyze(frame, actions=['gender', 'age', 'emotion'])\n",
    "\n",
    "    # Wypisanie wyników\n",
    "    #print(\"Płeć: \", result[\"gender\"])\n",
    "    #print(\"Wiek: \", result[\"age\"])\n",
    "    #print(\"Emocje: \", result[\"emotion\"])\n",
    "\n",
    "\n",
    "    # Wypisanie emocji na obrazie\n",
    "    \n",
    "    if max_emotion[0]=='happy':\n",
    "        #print(gender)\n",
    "        if gender=='Man':\n",
    "            cv2.putText(frame, \"ZNALEZIONY !!! \", (10, 40), font, 0.7, (0, 255, 0), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, \"ZNALEZIONA !!! \", (10, 40), font, 0.7, (0, 255, 0), 2)\n",
    "        cv2.putText(frame, emotion_dict[max_emotion[0]], (10, 450), font, 0.7, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Kandydat\", frame)\n",
    "    elif max_emotion[0]=='angry':\n",
    "        cv2.putText(frame, emotion_dict[max_emotion[0]], (10, 450), font, 0.7, (0, 0, 255), 2)\n",
    "    elif max_emotion[0]=='sad':\n",
    "        cv2.putText(frame, emotion_dict[max_emotion[0]], (10, 450), font, 0.7, (0, 200, 250), 2)\n",
    "    elif max_emotion[0]=='fear':\n",
    "        cv2.putText(frame, emotion_dict[max_emotion[0]], (10, 450), font, 0.7, (0, 0, 0), 2)\n",
    "    else:\n",
    "        cv2.putText(frame, emotion_dict[max_emotion[0]], (10, 450), font, 0.7, (150, 150, 150), 2)\n",
    "\n",
    "    wx, wy, ww, wh = cv2.getWindowImageRect(\"Kamera\")\n",
    "    #frame = cv2.resize(frame, (ww, wh)) # zmiana rozmiaru do rozmiarów okna\n",
    "    cv2.imshow(\"Kamera\", frame)\n",
    "\n",
    "    # Jeśli naciśnięto klawisz 'q', zakończ pętlę\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Zwolnienie kamery i zamknięcie okna\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**********************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "logo = cv2.imread(\"img\\mechatronika2.png\")\n",
    "# Wczytanie obrazu kamery\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "\n",
    "# Wczytanie logo\n",
    "logo = cv2.imread(\"logo.png\", -1)\n",
    "\n",
    "# Ustawienie rozmiaru logo do rozmiaru obrazu kamery\n",
    "logo = cv2.resize(logo, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "# Konwersja logo do odpowiadającego typu danych obrazu kamery\n",
    "logo = cv2.cvtColor(logo, cv2.COLOR_BGRA2RGBA)\n",
    "\n",
    "# Utworzenie miejsca dla logo\n",
    "img1_bg = cv2.bitwise_and(frame,frame,mask = mask_inv)\n",
    "img2_fg = cv2.bitwise_and(logo,logo,mask = mask)\n",
    "\n",
    "# Dodanie logo do obrazu kamery\n",
    "dst = cv2.addWeighted(img1_bg,0.5,img2_fg,0.5,0)\n",
    "frame[0:rows, 0:cols ] = dst\n",
    "\n",
    "# Wyświetlenie obrazu z logiem\n",
    "cv2.imshow(\"Webcam with logo\", frame)\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# Zakończenie działania kamery\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from deepface import DeepFace\n",
    "\n",
    "# Inicjalizacja kamery internetowej\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Pobranie klatki z kamery\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Analiza klatki za pomocą deepface\n",
    "    #if DeepFace.functions.preprocess_face(frame, target_size=(224, 224), grayscale = True, enforce_detection = False, detector_backend = 'opencv', return_region = True, align = False):\n",
    "    result = DeepFace.analyze(frame, actions=['age', 'emotion', 'face_location'], enforce_detection=False)\n",
    "    # Pobranie koordynatów twarzy\n",
    "    if len(result[\"face_location\"]) > 0:\n",
    "        x, y, w, h = result[\"face_location\"]\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "\n",
    "    # Rysowanie prostokątu wokół twarzy\n",
    "    \n",
    "\n",
    "    # Wypisanie wyników\n",
    "    #print(\"Płeć: \", result[\"gender\"])\n",
    "    #print(\"Wiek: \", result[\"age\"])\n",
    "    #print(\"Emocje: \", result[\"emotion\"])\n",
    "\n",
    "    # Wypisanie wyników na klatce\n",
    "    \n",
    "    #cv2.putText(frame, \"Plec: {}\".format(result[\"gender\"]), (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    cv2.putText(frame, \"Wiek: {}\".format(result[\"age\"]), (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    cv2.putText(frame, \"Emocje: {}\".format(result[\"emotion\"]), (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    \n",
    "    # Rysowanie prostokątów wokół wykrytych twarzy\n",
    "    #x, y, w, h = faces[0]:\n",
    "    #cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    # Wyświetlenie klatki\n",
    "    cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "    # Jeśli naciśnięto klawisz 'q', zakończ pętlę\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Zwolnienie kamery i zamknięcie okna\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Wczytanie logo\n",
    "logo = cv2.imread(\"img\\mechatronika2.png\")\n",
    "\n",
    "# Utworzenie obiektu kamery\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Pobranie pojedynczego kadru z kamery\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Dodanie logo do górnego prawego rogu obrazu\n",
    "    rows, cols, channels = logo.shape\n",
    "    roi = frame[0:rows, 0:cols]\n",
    "    logo2gray = cv2.cvtColor(logo, cv2.COLOR_BGR2GRAY)\n",
    "    ret, mask = cv2.threshold(logo2gray, 10, 255, cv2.THRESH_BINARY)\n",
    "    mask_inv = cv2.bitwise_not(mask)\n",
    "    frame_bg = cv2.bitwise_and(roi, roi, mask=mask_inv)\n",
    "    logo_fg = cv2.bitwise_and(logo, logo, mask=mask)\n",
    "    dst = cv2.add(frame_bg, logo_fg)\n",
    "    frame[0:rows, 0:cols] = dst\n",
    "\n",
    "    # Wyświetlenie obrazu z kamery z logo\n",
    "    cv2.imshow(\"Camera\", frame)\n",
    "\n",
    "    # Zakończenie programu po naciśnięciu klawisza 'q'\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Zwolnienie obiektu kamery i zamknięcie okna\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "path_xml = \"C:/Users/kozol/miniconda3/pkgs/opencv-4.6.0-py310ha7641e4_2/Library/etc/haarcascades/\"\n",
    "f_cascade = cv2.CascadeClassifier(path_xml + \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "img = cv2.imread(\"img/lena.png\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "faces = f_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = e_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "pltImgCv(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepface",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cf6458a7a854acc88179376829cb6c570c7c0424e5bcedfcf9fbb5f242ae0661"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
